---
title: "Pipeline"
label: "guidance:pipeline"
hasContent: true
summary: This guidance decribes our pipeline process of collecting individual publications of data and turning them into national datasets.
---

One of our data principles is that data should be maintained as close to source as possible. This means that with land and housing data we often have over 350 sources that make a national dataset.

Our pipeline is the steps we take to collect data from each individual source, and transform that data into a national dataset.

<a data-flickr-embed="true" href="https://www.flickr.com/photos/mattlucht/49547009136/in/datetaken-public/" title="Brownfield_Land_Report_-_Google_Slides"><img src="https://live.staticflickr.com/65535/49547009136_f3c86e9e31_b.jpg" alt="Brownfield_Land_Report_-_Google_Slides"></a>

## Collect

The collector is the first step in our pipeline and it's primary purpose if to gather all of the resources that we know about:

* each night it visits every resource that we know about and checks whether it still exisits
* a daily [log is produced](/resource/log/2020-01-16) which records what the collector found
* if a resource has changed then we add that resource into our collection, as an example, [see the brownfield collection](https://github.com/digital-land/brownfield-land-collection/blob/master/dataset/brownfield-land.csv)

## Validate

The validation step.

## Convert

When a new resource is 

## Normalise

The normalisation step.

## Map

The mapping step.

## Harmonise

The harmonisation step.

## Transform

The transformation step.

